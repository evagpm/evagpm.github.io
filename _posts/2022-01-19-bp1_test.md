---
layout: post
title: Blog Post 1 Testing
---

## 1 Create a Database

We are going to create a database with with three datasets to efficiently access information

To do this, we will need the following imports


```python
import pandas as pd
import numpy as np
import sqlite3
```

### Temperatures table

The temperatures dataset includes the temperatures for each month of a year for thousands of stations. There is separate file for each decade worth of years, so we add that decade to the url. Let's look at the data table for the most recent decade.


```python
interval = "2011-2020"
temps_url = f"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/noaa-ghcn/decades/{interval}.csv"
temperatures = pd.read_csv(temps_url)
temperatures.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Year</th>
      <th>VALUE1</th>
      <th>VALUE2</th>
      <th>VALUE3</th>
      <th>VALUE4</th>
      <th>VALUE5</th>
      <th>VALUE6</th>
      <th>VALUE7</th>
      <th>VALUE8</th>
      <th>VALUE9</th>
      <th>VALUE10</th>
      <th>VALUE11</th>
      <th>VALUE12</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ACW00011604</td>
      <td>2011</td>
      <td>-83.0</td>
      <td>-132.0</td>
      <td>278.0</td>
      <td>1040.0</td>
      <td>1213.0</td>
      <td>1663.0</td>
      <td>1875.0</td>
      <td>1723.0</td>
      <td>1466.0</td>
      <td>987.0</td>
      <td>721.0</td>
      <td>428.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ACW00011604</td>
      <td>2012</td>
      <td>121.0</td>
      <td>-98.0</td>
      <td>592.0</td>
      <td>646.0</td>
      <td>1365.0</td>
      <td>1426.0</td>
      <td>1771.0</td>
      <td>1748.0</td>
      <td>1362.0</td>
      <td>826.0</td>
      <td>620.0</td>
      <td>-234.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ACW00011604</td>
      <td>2013</td>
      <td>-104.0</td>
      <td>-93.0</td>
      <td>-48.0</td>
      <td>595.0</td>
      <td>NaN</td>
      <td>1612.0</td>
      <td>1855.0</td>
      <td>1802.0</td>
      <td>1359.0</td>
      <td>1042.0</td>
      <td>601.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



The way this data is set up is not tidy, since there are 12 temperatures values in each observation. To make it tidy, we want to have one row for each month. The temperature values are also in hundreths of a degree, so we want to divide them by degree. Let's make a function to do this.


```python
def prep_temp_df(df):
    """
    This function tidys and cleans the data.
    It makes each observation be the temperature for a station, year, and month
    and neatens the new columns of month and temp
    
    Input: df - a dataframe of temperatures
    
    Outputs a restructured dataframe of the temperatures
    """
    #We want to keep ID and Year as columns in the transformed table
    df = df.set_index(keys=["ID", "Year"])
    
    #Convert table
    df = df.stack()
    df = df.reset_index()
    
    #Make the new columns for Month and Temp look nice
    df = df.rename(columns = {"level_2"  : "Month" , 0 : "Temp"})
    df["Month"] = df["Month"].str[5:].astype(int)
    df["Temp"]  = df["Temp"] / 100
    return(df)
```

Now we want to create a database.


```python
conn = sqlite3.connect("climate.db")
```

Now we want to add the data, one decade file at a time. So for each decade, we will read in data from the url, prepare it, and add it to the temperatures table.


```python
#List with the start of each decade
decades = np.arange(1901, 2021, 10)

for start in decades:
    interval = str(start) + "-" + str(start+9)
    temps_url = f"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/noaa-ghcn/decades/{interval}.csv"
    
    #Create iterator to reach in chunk
    df_iter = pd.read_csv(temps_url, chunksize = 100000)
    
    #Iterate through the file, adding chunks
    for df in df_iter:
        cleaned = prep_temp_df(df)
        cleaned.to_sql("temperatures", conn, if_exists = "append", index = False)
```

### Stations table

Now we will get our next table from its url.


```python
stations_url = "https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/noaa-ghcn/station-metadata.csv"
stations = pd.read_csv(stations_url)
stations.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>LATITUDE</th>
      <th>LONGITUDE</th>
      <th>STNELEV</th>
      <th>NAME</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ACW00011604</td>
      <td>57.7667</td>
      <td>11.8667</td>
      <td>18.0</td>
      <td>SAVE</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AE000041196</td>
      <td>25.3330</td>
      <td>55.5170</td>
      <td>34.0</td>
      <td>SHARJAH_INTER_AIRP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AEM00041184</td>
      <td>25.6170</td>
      <td>55.9330</td>
      <td>31.0</td>
      <td>RAS_AL_KHAIMAH_INTE</td>
    </tr>
  </tbody>
</table>
</div>



We will want to use this table to match countries. It turns out the first two characters of the ID match the FIPS 10-4 country code, so let's add that to our table


```python
stations["FIPS"] = stations["ID"].str[0:2]
```

Now we can add this table directly to the database


```python
stations.to_sql("stations", conn, if_exists = "replace", index = False)
```

### Countries table

Lastly we are going to add our countries table. We can get it from the url below.


```python
countries_url = "https://raw.githubusercontent.com/mysociety/gaze/master/data/fips-10-4-to-iso-country-codes.csv"
countries = pd.read_csv(countries_url)
countries.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FIPS 10-4</th>
      <th>ISO 3166</th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AF</td>
      <td>AF</td>
      <td>Afghanistan</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AX</td>
      <td>-</td>
      <td>Akrotiri</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>AL</td>
      <td>Albania</td>
    </tr>
  </tbody>
</table>
</div>



We are going to run into problems with SQL if the column names have spaces, so let's shorten those. It might also make sense to change Name to Country.


```python
countries = countries.rename(columns = {"FIPS 10-4":"FIPS", "ISO 3166":"ISO", "Name":"Country"})
countries.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>FIPS</th>
      <th>ISO</th>
      <th>Country</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AF</td>
      <td>AF</td>
      <td>Afghanistan</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AX</td>
      <td>-</td>
      <td>Akrotiri</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>AL</td>
      <td>Albania</td>
    </tr>
  </tbody>
</table>
</div>



Then we can add this table to our database


```python
countries.to_sql("countries", conn, if_exists = "replace", index = False)
```

Since we are done adding to our database, we need to close the connection.


```python
conn.close()
```

## 2 Write a Query Function

Now we are going to write a function that will create table from the database using SQL

We want to look at temperatures for a given countries for a given month in a range of years. We want the dataframe to have columns for the station name, latititude, longitude, and country, as well as year, month, and temperature of the reading.   

To get this we will make a command. The command will select all of the columns from the abreviated name of table they came from. It will join the temperatures table with station, on id, and countries, on FIPS in order to do this. In the WHERE statement, we will include the conditions.


```python
def query_climate_database(country, year_begin, year_end, month):
    """
    This function creates a dataframe of temperatures for stations in a country
    for a given month and years from the climate database
    
    Inputs:
    country - the country to look in
    year_begin - the first year to gather data for
    year_end - the last year to gather data for
    month - the month of tempterature to look at
    
    Outputs a dataframe according to the specifications
    """
    
    #The command pulls data from all three tables by joining them
    cmd = """
    SELECT S.name, S.latitude, S.longitude, C.country, T.year, T.month, T.temp
    FROM temperatures T
    LEFT JOIN stations S ON T.id = S.id
    LEFT JOIN countries C ON C.FIPS = S.FIPS
    WHERE C.country= \"""" + str(country) + """\"
    AND T.year >=""" + str(year_begin) + """
    AND T.year <=""" + str(year_end) + """
    AND T.month =""" + str(month)
    
    #Open the connection to execute the command
    conn = sqlite3.connect("climate.db")
    df = pd.read_sql_query(cmd, conn)
    conn.close()
    return df
```

Lets do an example where we look at temperatures in August for stations in Germany from 2009 to 2012.


```python
query_climate_database("Germany", 2009, 2012, 8).head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NAME</th>
      <th>LATITUDE</th>
      <th>LONGITUDE</th>
      <th>Country</th>
      <th>Year</th>
      <th>Month</th>
      <th>Temp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>BREMEN</td>
      <td>53.0464</td>
      <td>8.7992</td>
      <td>Germany</td>
      <td>2009</td>
      <td>8</td>
      <td>18.46</td>
    </tr>
    <tr>
      <th>1</th>
      <td>BREMEN</td>
      <td>53.0464</td>
      <td>8.7992</td>
      <td>Germany</td>
      <td>2010</td>
      <td>8</td>
      <td>17.14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>TRIER</td>
      <td>49.7517</td>
      <td>6.6467</td>
      <td>Germany</td>
      <td>2009</td>
      <td>8</td>
      <td>19.53</td>
    </tr>
  </tbody>
</table>
</div>



## 3 Write a Geographic Scatter Function for Yearly Temperature Increases

Our next task is to create a function our query that will address the following question:

*How does the average yearly change in temperature vary within a given country?*

To do this we are going to group the data by station and find the change using linear regression. For this we will need a function to use in the apply.


```python
from sklearn.linear_model import LinearRegression

def coef(data_group):
    """
    This function finds the linear regression equation for a data group
    
    Input: data_group - as data group from the groupby function
    
    Output the rounded first coefficient of the equation
    """
    x = data_group[["Year"]]
    y = data_group["Temp"]
    LR = LinearRegression()
    LR.fit(x,y)
    return round(LR.coef_[0],3)
```

We will do this with plotly.


```python
from plotly import express as px
```

Make function


```python
def temperature_coefficient_plot(country, year_begin, year_end, month, min_obs, **kwargs):
    df = query_climate_database(country, year_begin, year_end, month)
    obs = df.groupby(["NAME"])["Month"].transform(np.sum) / month
    df = df[obs >= min_obs]
    df = df.reset_index()
    coefs = df.groupby(["NAME", "LATITUDE", "LONGITUDE"]).apply(coef).reset_index()
    coefs["Yearly\nIncrease"] = coefs[0]
    title = "Yearly Temperature Increase in Month " + str(month)
    title += "for stations in " + country +" "+ str(year_begin)
    title += "-" + str(year_end)
    fig = px.scatter_mapbox(coefs,
                            lat = "LATITUDE",
                            lon = "LONGITUDE",
                            color = "Yearly\nIncrease",
                            color_continuous_midpoint = 0,
                            hover_name = "NAME",
                            title = title,
                            mapbox_style = "carto-positron",
                            **kwargs)
    return fig
```


```python
color_map = px.colors.diverging.RdGy_r # choose a colormap

fig = temperature_coefficient_plot("India", 1980, 2020, 1, 
                                   min_obs = 10,
                                   zoom = 2,
                                   #mapbox_style="carto-positron",
                                   color_continuous_scale=color_map)
```
We want to have the figure on our blog.

```python
from plotly.io import write_html
write_html(fig, "plot3.html")
```

Now adding chart

{% include fig3.html %}

See beautiful chart